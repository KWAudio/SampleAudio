{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17533544-7dde-496e-9874-20ff3b2e98e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6caae257-1758-4289-96da-8ca5e03c6e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tiktoken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a553ed38-8d57-4a98-a7f3-f03fde06ec50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import torch\n",
    "\n",
    "# 디바이스 설정\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# 모델 불러오기\n",
    "model = whisper.load_model(\"turbo\") \n",
    "\n",
    "# (1) 음성 파일 이름으로 바로 입력\n",
    "result = model.transcribe(\"/home/ehost1/YS/Dataset/Old/노인남여_노인대화70_M_jang0972_60_수도권_실내_76454.wav\")\n",
    "\n",
    "# (2) 음성 파일을 불러들여서 텐서 형태로 입력\n",
    "#audio = whisper.load_audio(\"/home/ehost1/YS/Dataset/Old/노인남여_노인대화70_M_jang0972_60_수도권_실내_76450.wav\", sr=16000)\n",
    "#result = model.transcribe(audio, fp16=False, language='ko')\n",
    "\n",
    "# 결과 확인해보기\n",
    "result['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58991523-e714-46b6-b91b-2cd9ce20e5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import torch\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# 디바이스 설정 (GPU 사용 가능 여부에 따라)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 사용할 모델 리스트\n",
    "models = ['small', 'turbo', 'large']\n",
    "\n",
    "# 테스트할 음성 파일들이 있는 폴더 경로 설정\n",
    "audio_folder = '/home/ehost1/YS/Dataset/Sample/'\n",
    "audio_files = [f for f in os.listdir(audio_folder) if f.endswith('.wav')]\n",
    "\n",
    "# 결과를 저장할 디렉토리\n",
    "output_dir = '/home/ehost1/YS/Whisper_results/'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 결과 저장용 딕셔너리\n",
    "model_times = {model: [] for model in models}\n",
    "model_texts = {model: [] for model in models}\n",
    "\n",
    "# 모델마다 번갈아가며 테스트\n",
    "for model_name in models:\n",
    "    # 모델 불러오기\n",
    "    model = whisper.load_model(model_name).to(device)\n",
    "    print(f\"Testing with model: {model_name}\")\n",
    "    \n",
    "    # 각 음성 파일에 대해 처리\n",
    "    for audio_file in audio_files:\n",
    "        audio_path = os.path.join(audio_folder, audio_file)\n",
    "        \n",
    "        # 처리 시간 측정 시작\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # 음성 파일 처리 및 텍스트 변환\n",
    "        result = model.transcribe(audio_path)\n",
    "        \n",
    "        # 처리 시간 기록\n",
    "        processing_time = time.time() - start_time\n",
    "        model_times[model_name].append(processing_time)\n",
    "        \n",
    "        # 결과 텍스트 저장\n",
    "        result_text = result['text']\n",
    "        output_file = os.path.join(output_dir, f\"{model_name}_{audio_file}.txt\")\n",
    "        \n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(result_text)\n",
    "        \n",
    "        model_texts[model_name].append(result_text)\n",
    "        \n",
    "    # 각 모델별 평균 처리 시간 출력\n",
    "    avg_time = np.mean(model_times[model_name])\n",
    "    print(f\"Model: {model_name} | Average Time: {avg_time:.2f} seconds\")\n",
    "\n",
    "# 모델별 결과 비교 (평균 시간)\n",
    "for model_name in models:\n",
    "    avg_time = np.mean(model_times[model_name])\n",
    "    print(f\"Average time for model {model_name}: {avg_time:.2f} seconds\")\n",
    "\n",
    "# 각 모델의 텍스트 결과 저장을 위한 디렉토리\n",
    "summary_dir = '/home/ehost1/YS/Whisper_summary/'\n",
    "os.makedirs(summary_dir, exist_ok=True)\n",
    "\n",
    "# 모델별 텍스트 결과를 summary 파일로 저장\n",
    "for model_name in models:\n",
    "    summary_file = os.path.join(summary_dir, f\"{model_name}_summary.txt\")\n",
    "    with open(summary_file, 'w', encoding='utf-8') as f:\n",
    "        for text in model_texts[model_name]:\n",
    "            f.write(text + \"\\n\")\n",
    "    \n",
    "    print(f\"Text results for model {model_name} saved to {summary_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ef3328-8445-45d8-a7c3-294d10d3ca13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu_38",
   "language": "python",
   "name": "tf_gpu_38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
